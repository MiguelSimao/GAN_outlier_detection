#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Aug  8 16:54:29 2018

@author: simao
"""

import numpy as np

def l2_norm(X,Y):
    ''' 
    Calculates the mean and std of the norm between samples generated by a gan 
    (Y) and training samples (X). Inputs and outputs are assumed to be numpy
    arrays.
    
    X and Y are (n_samples, n_features)
    output L is (n_samples(Y), 2)
    L[:,0] is the mean of (X[:] - Y[i])**2
    L[:,1] is the std
    '''
    
    if np.ndim(Y) == 1:
        M = 1
    else:
        M = Y.shape[0]
    
    mean = np.zeros((M,))
    std = np.zeros((M,))
    
    # Compute distance between samples of Y and X
    for i in range(M):
        sample = Y[i]
        
        # difference
        d = (X - sample) ** 2
        d = np.sqrt(np.sum(d, axis=1))
        mean[i] = np.mean(d)
        std[i]  = np.std(d)
    
    return (np.mean(mean), np.mean(std))

def class_l2_norm(X, T, Xg, Tg):
    '''
    Calculates the similarity between samples per class.
    Based on the 'l2_norm' function.
    
    X are the true samples, T the true targets (indexes)
    Xg are the gen'ed samples, Tg the gen'ed targets (indexes)
    '''
    
    # Find target intersection (only compare indexes present in both sets)
    t = np.unique(T)
    tg = np.unique(Tg)
    ti = np.intersect1d(t,tg)
    if len(ti) != len(tg):
        print('Disjunction  between data sets.')
        print('Dropped classes:')
        print(np.setxor1d(t,tg))
        print('Included classes:')
        print(ti)
    
    output = np.zeros((len(ti), 3))
    
    for i in range(len(ti)):
        tind = ti[i]
        x = X[T==tind]
        xg = Xg[Tg==tind]
        output[i,0] = tind
        output[i,1], output[i,2] = l2_norm(x, xg)
    return output
    
    